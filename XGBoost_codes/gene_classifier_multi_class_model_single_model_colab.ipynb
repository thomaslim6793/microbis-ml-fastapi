{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "df = pd.read_csv('/content/drive/MyDrive/microbis_data/amr_data_long_format_no_antibiotics_preprocessed_08_24.csv',\n",
    "                 dtype={'detected_variant': 'str', 'detected_binary': 'str'})\n",
    "\n",
    "# Define df_gene_bin \n",
    "df_gene_mult = df.drop(columns=['Isolate Id', 'detected_binary'])\n",
    "df_gene_mult = df_gene_mult.dropna(subset=['detected_variant'])\n",
    "\n",
    "# Define the target variable (y) and the feature set (X)\n",
    "y = df_gene_mult['detected_variant']\n",
    "X = df_gene_mult.drop(columns=['detected_variant'])\n",
    "\n",
    "# Convert categorical columns to 'category' dtype\n",
    "categorical_columns = ['Phenotype', 'Species', 'Family', 'Country', 'State', \n",
    "                       'Gender', 'Age Group', 'Speciality', 'Source', 'In / Out Patient', 'gene']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].astype('category')\n",
    "\n",
    "# Convert any numeric columns to the appropriate type if necessary\n",
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Optionally convert other numeric-like columns that might be object types\n",
    "for col in numeric_columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Identify classes with fewer than a certain number of instances (e.g., less than 10)\n",
    "min_class_count = 10  # Set the minimum count threshold\n",
    "class_counts = y.value_counts()\n",
    "rare_classes = class_counts[class_counts < min_class_count].index\n",
    "\n",
    "# Filter out the rows with these rare classes\n",
    "X = X[~y.isin(rare_classes)]\n",
    "y = y[~y.isin(rare_classes)]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_dist = {\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'min_child_weight': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier with default parameters\n",
    "model = xgb.XGBClassifier(\n",
    "    tree_method='gpu_hist',  # Use the GPU-accelerated histogram algorithm\n",
    "    gpu_id=0,  # Use the first GPU\n",
    "    eval_metric='mlogloss',  # Evaluation metric\n",
    "    use_label_encoder=False,  # To avoid deprecation warnings\n",
    "    enable_categorical=True  # Enable native handling of categorical features\n",
    ")\n",
    "\n",
    "# Perform RandomizedSearchCV with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=15,  # Number of different combinations to try\n",
    "    scoring='accuracy',  # Metric to optimize\n",
    "    cv=3,  # 5-fold cross-validation\n",
    "    verbose=1,  # Print progress\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to find the best model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the search\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best model test set accuracy: {accuracy}\")\n",
    "\n",
    "# Combine the best model and label encoder into a dictionary\n",
    "model_and_encoder = {\n",
    "    'model': best_model,\n",
    "    'label_encoder': label_encoder\n",
    "}\n",
    "\n",
    "# Save the combined object to a pkl file\n",
    "with open('/content/drive/MyDrive/microbis_data/gene_mult_classification_best.pkl', 'wb') as file:\n",
    "    pickle.dump(model_and_encoder, file)\n",
    "\n",
    "print(\"Best model and label encoder saved as 'gene_mult_classification_best.pkl'\")\n",
    "\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate metrics after training\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Save the metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'classification_report': report,\n",
    "    'confusion_matrix': conf_matrix.tolist()  # Convert to list for JSON serialization\n",
    "}\n",
    "\n",
    "with open('/content/drive/MyDrive/microbis_data/gene_mult_classification_best.json', 'w') as file:\n",
    "    json.dump(metrics, file)\n",
    "\n",
    "print(\"Model metrics saved as 'gene_mult_classification_best.json'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
